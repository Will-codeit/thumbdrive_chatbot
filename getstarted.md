# Getting Started with DeepSeek-V3 Thumb Drive

Welcome! Your AI assistant is ready to run in just a few clicks.

---

## ğŸš€ Quick Start (10 Seconds!)

### What You'll See When You Open the Thumb Drive:

```
ğŸ“ Your Thumb Drive
  â””â”€â”€ ğŸ“„ START_HERE.txt              â† Read this first!
  â””â”€â”€ ğŸ“„ START_DEEPSEEK.command      â† DOUBLE-CLICK THIS! (Recommended)
  â””â”€â”€ ğŸš€ Start DeepSeek.app           â† Or click this (needs approval)
  â””â”€â”€ ğŸ“‚ scripts/
  â””â”€â”€ ğŸ“„ readme.md
  â””â”€â”€ ğŸ“„ getstarted.md (this file)
```

### Just 2 Steps:

**Option 1 (RECOMMENDED):** Double-click `START_DEEPSEEK.command`
   - âœ… Works instantly on any Mac
   - âœ… No security warnings
   - âœ… Perfect for thumb drives

**Option 2:** Double-click `ğŸš€ Start DeepSeek.app`
   - âœ… Nice icon and professional look
   - âš ï¸  Requires one-time security approval (see below)

The launcher will:
- âœ… Check your Mac's hardware (RAM, storage, etc.)
- âœ… Show you a configuration screen (or use smart defaults)
- âœ… Download the AI model if needed (first time only)
- âœ… Start the server
- âœ… Open the chat interface

---

## âš ï¸ First Time Only: Security Warning (App Bundle Only)

**If using `ğŸš€ Start DeepSeek.app`**, macOS will block it the first time because it's from an "unidentified developer."

### How to Fix (30 seconds, only needed once):

1. **Right-click** (or Control+click) on `ğŸš€ Start DeepSeek.app`
2. Select **"Open"** from the menu
3. Click **"Open"** in the security dialog
4. Done! The app will now launch

**After this one-time step**, you can just double-click normally on any Mac.

ğŸ’¡ **TIP:** Using `START_DEEPSEEK.command` avoids this issue entirely!

---

## What You Need

- âœ… This thumb drive plugged into your Mac
- âœ… macOS 10.15 or later
- âœ… 8GB RAM minimum (16GB+ **strongly recommended** for best performance)
- âœ… Internet connection (first time only - for downloading the AI model)
- âœ… About 30-60 minutes for first-time setup (mostly waiting for download)

### ğŸ’­ How Does This Work with My RAM?

**The model doesn't fully load into RAM!** It uses **memory-mapping**:

| Your RAM | Model Downloaded | How It Works |
|----------|------------------|--------------|
| **8GB** | Q3_K_M (~24GB file) | Only ~6-8GB loads into RAM. Fast but slightly lower quality. |
| **16GB** | Q4_K_M (~40GB file) | Only ~8-12GB loads into RAM. Balanced quality. |
| **32GB+** | Q5_K_M (~50GB file) | ~12-16GB loads into RAM. High quality. |

**The system automatically picks the right model for your RAM!** You don't need to choose - it figures it out.

---

## ğŸ¨ Configuration Screen

The first time you run the app, you'll see a configuration dialog with two options:

### Option 1: Use Recommended Settings (One Click)
- System detects your RAM
- Automatically selects optimal settings
- Click "Use Recommended" and you're done!

### Option 2: Customize Everything
Choose your preferences:
- **Model Quality**: Q3_K_M (fast) â†’ Q6_K (best quality)
- **Context Window**: 2048 tokens â†’ 16384 tokens
- **GPU Acceleration**: 20 layers â†’ 99 layers
- **Advanced**: Port, threads, parallel requests

All settings are saved, so you only configure once!

---

## After Setup: Using the AI

Once the server starts, the app automatically opens a chat interface in your browser.

### Chat Interface Features:

- ğŸ’¬ **Type your questions** in the text box
- ğŸ¤– **AI responds** with detailed answers
- ğŸ“ **Conversation history** saved in the window
- ğŸ”„ **Keep chatting** - the AI remembers context

### Example Prompts:

```
"Write a Python function to calculate fibonacci numbers"

"Explain quantum computing in simple terms"

"Help me debug this JavaScript code: [paste code]"

"Write a professional email asking for a meeting"
```

---

## Stopping the Server

When you're done:

1. Go to the Terminal window (shows server logs)
2. Press `Ctrl + C` (hold Control and press C)
3. The server will shut down
4. You can safely eject the thumb drive

Or just close the Terminal window and the server stops automatically.

---

## Alternative: Terminal Method (Advanced Users)

If you prefer the command line:

```bash
cd /Volumes/YOUR_DRIVE_NAME/deep_seek_llama
./scripts/run.sh
```

This does the same thing as the app, but shows more technical details.

---

## Troubleshooting

### "The app is damaged and can't be opened"

This is macOS security. Follow the **First Time Security Warning** steps above.

### App won't launch at all

```bash
# In Terminal:
cd /Volumes/YOUR_DRIVE_NAME/deep_seek_llama
chmod +x scripts/*.sh
./scripts/create-autorun.sh
```

This recreates the app with correct permissions.

### Out of memory / Computer is slow

The AI needs RAM. Try:
1. Close other applications (Chrome, Photoshop, etc.)
2. Restart your Mac
3. Run the app again - it will use a smaller model

### Download fails

If the model download fails:
1. Check your internet connection
2. Make sure you have 50GB+ free space on the thumb drive
3. Try again - the app will resume where it left off

### Port already in use

If you see "Port 8080 already in use":
1. Stop any other servers running on your Mac
2. Or: Edit settings through the app's customize option
3. Choose a different port (like 8081)

### Still having issues?

- Read `readme.md` for technical documentation
- Check `MEMORY_EXPLAINED.md` to understand how it works
- Look in the `logs/` folder for error messages

---

## What Can You Use This For?

- ğŸ’» **Coding assistance** - Write, debug, or explain code in any language
- ğŸ“ **Writing** - Generate content, fix grammar, summarize text
- ğŸ“ **Learning** - Ask questions and get detailed explanations
- ğŸ“Š **Data analysis** - Help interpreting data and creating visualizations
- ğŸ” **Research** - Summarize articles, answer questions
- ğŸ¨ **Creative work** - Brainstorm ideas, write stories, create content

All running 100% locally on your Mac - no data sent to the cloud!

---

## Tips for Best Performance

1. **Use Apple Silicon Macs** (M1, M2, M3, M4) for best speed
2. **More RAM = Better** - 32GB or more is ideal
3. **Close heavy apps** - Free up RAM for the AI
4. **First run takes longest** - 40GB download + setup (~45 min)
5. **After first run** - Starts in ~30 seconds!

### ğŸ’¡ Thumb Drive Speed?

**Don't worry about thumb drive speed affecting AI performance!**

- The model loads into your Mac's RAM at startup (10 sec - 3 min)
- After loading, the AI runs entirely from RAM
- Thumb drive speed doesn't affect inference speed
- Even a slow USB 2.0 drive gives full-speed AI once loaded

---

## Important Notes

### Privacy
- âœ… Everything runs on YOUR computer
- âœ… No internet required after initial download
- âœ… Your conversations never leave your Mac
- âœ… Completely private and secure

### Internet Usage
- âœ… Only needed once to download the model (~25-50GB)
- âœ… After that, works completely offline
- âœ… Perfect for airplanes, coffee shops, anywhere!

### Disk Space
- âœ… Model takes ~25-50GB (depends on your RAM)
- âœ… Use a 64GB+ thumb drive
- âœ… 128GB+ recommended for comfort

---

## Quick Reference

| Action | How To Do It |
|--------|-------------|
| **Start the AI** | Double-click `START_DEEPSEEK.command` (Recommended) or `ğŸš€ Start DeepSeek.app` |
| **Stop the server** | Press `Ctrl + C` in Terminal window |
| **Change settings** | Run the app again, choose "Customize" |
| **Open chat** | Automatic after server starts |
| **Get help** | Read `START_HERE.txt` or `readme.md` |

---

## Need More Help?

1. **START_HERE.txt** - Quick visual guide at the root
2. **docs/readme.md** - Detailed technical documentation  
3. **docs/MEMORY_EXPLAINED.md** - How the memory system works
4. **docs/INSTALLATION.md** - Advanced setup and troubleshooting

---

**Happy AI-ing! ğŸš€ğŸ¤–**

Remember: Just double-click `START_DEEPSEEK.command` (recommended) or `ğŸš€ Start DeepSeek.app` and everything else is automatic!
